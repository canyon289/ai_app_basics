{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e4fdaf-ee74-431e-8445-91dbc7830c1c",
   "metadata": {},
   "source": [
    "# Initial Prompt Engineering and Evals\n",
    "Let's go through the first steps of AI app building.\n",
    "What we'll be doing is a building an LLM that can classify text into two categories; American Football Team or Australian Football Team\n",
    "\n",
    "## Step 1: Vibes\n",
    "This one is easy and my wager is most of you have already done this.\n",
    "You get get a model, some data, try some prompts, and see what happens.\n",
    "\n",
    "Though it feels informal this currently just a really great way to get staretd.\n",
    "\n",
    "### Task: Initial Prompt and Output\n",
    "Get a model to output whether a team name is of an Australian Football Team or an American football team.\n",
    "Since you're the app designer you need to design the format.\n",
    "\n",
    "However once we feel things out we want to quickly move to the next step.\n",
    "\n",
    "## Step 2: Repeatable evals\n",
    "This is where most people drop off. \n",
    "Vibes are good but its hard to repeatably scale random vibe checking.\n",
    "\n",
    "### Task: Eval Harness\n",
    "Write a repeatable eval script that can test all American and Australian team names.\n",
    "We included a couple of tasks\n",
    " 1. Full city and team name provided\n",
    " 2. Only team name provided\n",
    " 3. An article about the team\n",
    "\n",
    "**Note**\n",
    "The goal here is NOT to build a perfect classifier. Rather we want you to think hard about how to build a repeatable eval, eval metrics, and pitfalls of evals. Don't stress about not getting a 100%, but do make tweaks to see how high of a score you can get!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7d49a-001a-43c8-8ff5-f3f82f592880",
   "metadata": {},
   "source": [
    "## Functionality Test\n",
    "A quick code block to check all the wiring is correct with python and Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e358d28f-4e7c-4100-a1ac-ca2d42b597ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model \"gemma2:2b\" not found, try pulling it first (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     15\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mSay hello to the class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43msingle_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36msingle_turn\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msingle_turn\u001b[39m(prompt):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     response: ChatResponse = \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m      \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/ai_app_basics/gemma-app/lib/python3.11/site-packages/ollama/_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/ai_app_basics/gemma-app/lib/python3.11/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/ai_app_basics/gemma-app/lib/python3.11/site-packages/ollama/_client.py:122\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model \"gemma2:2b\" not found, try pulling it first (status code: 404)"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "model = 'gemma2:2b'\n",
    "\n",
    "def single_turn(prompt):\n",
    "    response: ChatResponse = chat(model=model, messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "      },\n",
    "    ])\n",
    "    return response['message']['content']\n",
    "\n",
    "prompt = \"Say hello to the class\"\n",
    "single_turn(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefdb9ba-5e3a-4687-bfd9-523f4eddfa9d",
   "metadata": {},
   "source": [
    "## Single Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "699e5070-20ac-4e5b-b5cf-d86acd7c8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "afl_team = \"Carlton Blues\"\n",
    "american_team = \"Tennessee Titans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0eb1eade-ef6d-4369-a0e6-6f4b2333701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Australian \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Output if this is an australian or american team, only print australian or american no other output: \" + f\"{afl_team}\"\n",
    "single_turn(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3219ad9-ff2c-47e9-aa64-d2457785ce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'American \\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Output if this is an australian or american team, only print australian or american no other output: \" + f\"{american_team}\"\n",
    "single_turn(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963de97-7f77-46e9-a78e-ca771a328692",
   "metadata": {},
   "source": [
    "## Extending evals\n",
    "Here are the list of AFL and NFL team names.\n",
    "Check if the model gets things right.\n",
    "This means you'll need to create a scoring and aggregation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15d75b16-d6d3-4250-95b1-ddf0229c4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "afl_clubs = [\n",
    "    \"Adelaide Crows\",\n",
    "    \"Brisbane Lions\",\n",
    "    \"Carlton Blues\",\n",
    "    \"Collingwood Magpies\",\n",
    "    \"Essendon Bombers\",\n",
    "    \"Fremantle Dockers\",\n",
    "    \"Geelong Cats\",\n",
    "    \"Gold Coast Suns\",\n",
    "    \"Greater Western Sydney (GWS) Giants\",\n",
    "    \"Hawthorn Hawks\",\n",
    "    \"Melbourne Demons\",\n",
    "    \"North Melbourne Kangaroos\",\n",
    "    \"Port Adelaide Power\",\n",
    "    \"Richmond Tigers\",\n",
    "    \"St Kilda Saints\",\n",
    "    \"Sydney Swans\",\n",
    "    \"West Coast Eagles\",\n",
    "    \"Western Bulldogs\"\n",
    "]\n",
    "\n",
    "nfl_teams = [\n",
    "    \"Arizona Cardinals\",\n",
    "    \"Atlanta Falcons\",\n",
    "    \"Baltimore Ravens\",\n",
    "    \"Buffalo Bills\",\n",
    "    \"Carolina Panthers\",\n",
    "    \"Chicago Bears\",\n",
    "    \"Cincinnati Bengals\",\n",
    "    \"Cleveland Browns\",\n",
    "    \"Dallas Cowboys\",\n",
    "    \"Denver Broncos\",\n",
    "    \"Detroit Lions\",\n",
    "    \"Green Bay Packers\",\n",
    "    \"Houston Texans\",\n",
    "    \"Indianapolis Colts\",\n",
    "    \"Jacksonville Jaguars\",\n",
    "    \"Kansas City Chiefs\",\n",
    "    \"Las Vegas Raiders\",\n",
    "    \"Los Angeles Chargers\",\n",
    "    \"Los Angeles Rams\",\n",
    "    \"Miami Dolphins\",\n",
    "    \"Minnesota Vikings\",\n",
    "    \"New England Patriots\",\n",
    "    \"New Orleans Saints\",\n",
    "    \"New York Giants\",\n",
    "    \"New York Jets\",\n",
    "    \"Philadelphia Eagles\",\n",
    "    \"Pittsburgh Steelers\",\n",
    "    \"San Francisco 49ers\",\n",
    "    \"Seattle Seahawks\",\n",
    "    \"Tampa Bay Buccaneers\",\n",
    "    \"Tennessee Titans\",\n",
    "    \"Washington Commanders\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b79f41ae-433d-4654-ae7e-23b7ca5a404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adelaide Crows: Australian\n",
      "Brisbane Lions: Australian\n",
      "Carlton Blues: Australian\n",
      "Collingwood Magpies: Australian\n",
      "Essendon Bombers: Australian\n",
      "Fremantle Dockers: Australian\n",
      "Geelong Cats: Australian\n",
      "Gold Coast Suns: Australian\n",
      "Greater Western Sydney (GWS) Giants: Australian\n",
      "Hawthorn Hawks: Australian\n",
      "Melbourne Demons: Australian\n",
      "North Melbourne Kangaroos: Australian\n",
      "Port Adelaide Power: Australian\n",
      "Richmond Tigers: Australian\n",
      "St Kilda Saints: Australian\n",
      "Sydney Swans: Australian\n",
      "West Coast Eagles: Australian\n",
      "Western Bulldogs: Australian\n",
      "Arizona Cardinals: American\n",
      "Atlanta Falcons: American\n",
      "Baltimore Ravens: American\n",
      "Buffalo Bills: American\n",
      "Carolina Panthers: American\n",
      "Chicago Bears: American\n",
      "Cincinnati Bengals: American\n",
      "Cleveland Browns: American\n",
      "Dallas Cowboys: American\n",
      "Denver Broncos: American\n",
      "Detroit Lions: American\n",
      "Green Bay Packers: American\n",
      "Houston Texans: American\n",
      "Indianapolis Colts: American\n",
      "Jacksonville Jaguars: American\n",
      "Kansas City Chiefs: American\n",
      "Las Vegas Raiders: American\n",
      "Los Angeles Chargers: American\n",
      "Los Angeles Rams: American\n",
      "Miami Dolphins: American\n",
      "Minnesota Vikings: American\n",
      "New England Patriots: American\n",
      "New Orleans Saints: American\n",
      "New York Giants: American\n",
      "New York Jets: American\n",
      "Philadelphia Eagles: American\n",
      "Pittsburgh Steelers: American\n",
      "San Francisco 49ers: American\n",
      "Seattle Seahawks: American\n",
      "Tampa Bay Buccaneers: American\n",
      "Tennessee Titans: American\n",
      "Washington Commanders: American\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "eval_map = {\"australian\": afl_name, \"american\": nfl_names}\n",
    "\n",
    "# Remove key let students code themselves\n",
    "score = []\n",
    "for nationality, teams in eval_map.items():\n",
    "    for team in teams:\n",
    "        prompt = \"Output if this is an australian or american team, only print australian or american no other output: \" + f\"{team}\"\n",
    "        #print(prompt)\n",
    "        response = single_turn(prompt).strip()\n",
    "        score.append(response.lower() == nationality)\n",
    "        print(f\"{team}: {response}\")\n",
    "\n",
    "print(np.array(score).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123bdf5e-bcd7-4b7c-9fb4-9ef9106a9f55",
   "metadata": {},
   "source": [
    "## Maing things harder. Taking just the team name\n",
    "What happens if we don't provide the full context. What happens to our score then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7545bd93-e8d3-461d-aaf5-2b134a9d4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "afl_names = ['Crows',\n",
    " 'Lions',\n",
    " 'Blues',\n",
    " 'Magpies',\n",
    " 'Bombers',\n",
    " 'Dockers',\n",
    " 'Cats',\n",
    " 'Suns',\n",
    " 'Giants',\n",
    " 'Hawks',\n",
    " 'Demons',\n",
    " 'Kangaroos',\n",
    " 'Power',\n",
    " 'Tigers',\n",
    " 'Saints',\n",
    " 'Swans',\n",
    " 'Eagles',\n",
    " 'Bulldogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfa87f3b-1d65-4754-b45d-568885c15080",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_teams = ['Cardinals',\n",
    " 'Falcons',\n",
    " 'Ravens',\n",
    " 'Bills',\n",
    " 'Panthers',\n",
    " 'Bears',\n",
    " 'Bengals',\n",
    " 'Browns',\n",
    " 'Cowboys',\n",
    " 'Broncos',\n",
    " 'Lions',\n",
    " 'Packers',\n",
    " 'Texans',\n",
    " 'Colts',\n",
    " 'Jaguars',\n",
    " 'Chiefs',\n",
    " 'Raiders',\n",
    " 'Chargers',\n",
    " 'Rams',\n",
    " 'Dolphins',\n",
    " 'Vikings',\n",
    " 'Patriots',\n",
    " 'Saints',\n",
    " 'Giants',\n",
    " 'Jets',\n",
    " 'Eagles',\n",
    " 'Steelers',\n",
    " '49ers',\n",
    " 'Seahawks',\n",
    " 'Buccaneers',\n",
    " 'Titans',\n",
    " 'Commanders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06d3e9df-17b7-41ab-9ee4-39e9068ba161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinals: American\n",
      "Falcons: Australian\n",
      "Ravens: American\n",
      "Bills: American\n",
      "Panthers: Australian\n",
      "Bears: Australian\n",
      "Bengals: American\n",
      "Browns: American\n",
      "Cowboys: Australian\n",
      "Broncos: Australian\n",
      "Lions: Australian\n",
      "Packers: American\n",
      "Texans: American\n",
      "Colts: Australian\n",
      "Jaguars: Australian\n",
      "Chiefs: American\n",
      "Raiders: Australian\n",
      "Chargers: American\n",
      "Rams: American\n",
      "Dolphins: Australian\n",
      "Vikings: Australian\n",
      "Patriots: American\n",
      "Saints: Australian\n",
      "Giants: Australian\n",
      "Jets: American\n",
      "Eagles: Australian\n",
      "Steelers: American\n",
      "49ers: American\n",
      "Seahawks: American\n",
      "Buccaneers: American\n",
      "Titans: Australian\n",
      "Commanders: American\n",
      "Crows: Australian\n",
      "Lions: Australian\n",
      "Blues: Australian\n",
      "Magpies: Australian\n",
      "Bombers: Australian\n",
      "Dockers: Australian\n",
      "Cats: Australian\n",
      "Suns: Australian\n",
      "Giants: American\n",
      "Hawks: American\n",
      "Demons: Australian\n",
      "Kangaroos: Australian\n",
      "Power: Australian\n",
      "Tigers: Australian\n",
      "Saints: Australian\n",
      "Swans: Australian\n",
      "Eagles: Australian\n",
      "Bulldogs: Australian\n",
      "0.67\n"
     ]
    }
   ],
   "source": [
    "eval_map = {\"american\": nfl_teams, \"australian\": afl_names}\n",
    "\n",
    "core = []\n",
    "\n",
    "for nationality, teams in eval_map.items():\n",
    "    for team in teams:\n",
    "        team = team.rsplit(maxsplit =1)[-1]\n",
    "        prompt = \"Output if this is an australian or american team, only print australian or american no other output: \" + f\"{team}\"\n",
    "        response = single_turn(prompt).strip()\n",
    "        score.append(response.lower() == nationality)\n",
    "        print(f\"{team}: {response}\")\n",
    "print(np.array(score).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dab1b-83fe-4439-9e69-aa78b43a3456",
   "metadata": {},
   "source": [
    "## News Articles\n",
    "Now try this for some long form articles. This time we won't give you an answer key, we'll let you figure things out.\n",
    "\n",
    "\n",
    "TODO: Ravin will fill this in. But its basically the same as above. Instead of a team name it'll take in what is a synthetically generated news article and classify it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
