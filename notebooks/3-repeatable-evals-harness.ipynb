{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Repeatable Evaluations with an Eval Harness  \n",
    "\n",
    "After experimenting informally, we need a **systematic way to measure performance**. This part introduces an **evaluation harness**—a structured script for running batch tests across multiple inputs.  \n",
    "\n",
    "We’ll cover:  \n",
    "- **Defining evaluation criteria** based on observed patterns.  \n",
    "- **Running batch tests** using a dataset of team names.  \n",
    "- **Expanding evaluation** to real-world data, like news articles.  \n",
    "\n",
    "By the end, you’ll have a **repeatable evaluation process**, ensuring that our AI system’s performance is measurable and consistent across different inputs.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
