{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Vibe-Based Evaluation  \n",
    "\n",
    "Now that we have a working MVP for our classification, itâ€™s time to test itâ€”but before diving into structured evaluation, weâ€™ll rely on **intuition and experimentation**.  \n",
    "\n",
    "In this part, weâ€™ll:  \n",
    "- **Try different prompts** to explore how the model responds.  \n",
    "- **Observe and analyze** the modelâ€™s behavior across examples.  \n",
    "- **Identify weak spots** where results seem inconsistent or unreliable.  \n",
    "\n",
    "This phase mirrors how many LLM practitioners startâ€”tweaking and iterating based on \"vibes\" before committing to structured testing. Treat this as an **exploratory phase**: experiment, adjust, and get a feel for what works before formalizing evaluation criteria.  \n",
    "\n",
    "## How to do this\n",
    "We're going to be using Ollama's command line interface. \n",
    "You can access it by opening a terminal by running `ollama run gemma2:2b`\n",
    "\n",
    "From there you will have access to a chat client.\n",
    "\n",
    "## Our goal\n",
    "We want an LLM that can tell us if a string of text is about either an American Football team, or an Australian one.\n",
    "For example, here;s two team names the Adelaide Crows, or Tennesee Titans.\n",
    "However we may also have a string like \"The Tennesee Titans scored a touch down in the 3rd quarter\" or an even longer string.\n",
    "\n",
    "We want this classifier  output either America, or Australia.\n",
    "\n",
    "**Your task is to get a classification of whether this about American football or Australian football**. Ideally we just want the string American or Australian\n",
    "\n",
    "Start prompting the LLM to see what results you get. Use your intuition to iterate to the right behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Recap: What We Learned  \n",
    "\n",
    "### Getting started immediately\n",
    "* Just start exploring to get a sense of how things work\n",
    "* Rapid iteration will help you get a sense for how the LLM works\n",
    "\n",
    "### \"Prompt Engineering\" is a valid skill\n",
    "* Just like people LLMs \"feel\" like they have different behaviors\n",
    "* Knowing how to craft working prompts is a very useful skill\n",
    "  * It takes practice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
